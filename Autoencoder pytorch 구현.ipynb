{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vkVqhhpGPu3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOHZoyIgPPdR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D #생성되는 이미지를 관찰하기 위함입니다. 3차원 플롯을 그리는 용도입니다.\n",
        "from matplotlib import cm # 데이터포인트에 색상을 입히는 것에 사용됩니다.\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCH = 10\n",
        "BATCH_SIZE = 64\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(\"using Device: \", DEVICE)"
      ],
      "metadata": {
        "id": "mCP4bwDhPTob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fashion MNIST 데이터셋을 사용해서 Autoencoder코드 구현 따라가기"
      ],
      "metadata": {
        "id": "W6-bFQcvP-Bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# trainset을 불러오는 코드 (datasets 안에 있는 예시 데이터셋)\n",
        "trainset = datasets.FashionMNIST(\n",
        "    root= './.data/',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transforms.ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "DuIA2l-mPleH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataloader 짜기 (데이터를 불러오는 과정과 초기 세팅해주기)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset = trainset,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = True,\n",
        "    num_workers = 2\n",
        ")\n",
        "\n",
        "# shuffle : 전체 학습데이터를 배열 인덱스와 관계없이 만드는 작업을 말함\n",
        "# 만일 안하게 되면 신경망이 해당 순서까지도 예측하기 때문에 과적합 발생할 수 있음 따라서 shuffle진행해줘야함\n",
        "\n",
        "# num_workers : default 값은 0임 how many subprocesses to use for data loading.  data 로딩을 위해 몇 개의 서브 프로세스를 사용할 것인지를 결정\n"
      ],
      "metadata": {
        "id": "3XBI249TQ7vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 오토인코더 모듈 정의\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Autoencoder,self).__init__()\n",
        "\n",
        "  # encoder정의하기 간단한 신경망으로 분류모델 처럼 생김\n",
        "    self.encoder = nn.Sequential(\n",
        "        # nn.Sequential을 사용해서 encoder와 decoder 두 모듈을 순차적으로 엮엊무\n",
        "        nn.Linear(28*28,128), #차원을 28*28에서 점차 줄여나가기\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128,64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64,12),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(12,3), #입력의 특징을 3차원으로 압축하기 => 출력값이 바로 잠재변수 할당\n",
        "    )\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.Linear(3,12), #디코더는 차원을 점차 28*28로 복원하기ㅏ\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(12,64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128,28*28),\n",
        "        nn.Sigmoid(),\n",
        "        # sigmoid 마지막에 0-1사이로 출력하는 함수 추가\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return encoded, decoded"
      ],
      "metadata": {
        "id": "QGoTjWaBRL6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = Autoencoder().to(DEVICE)\n",
        "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.005)\n",
        "# Adam을 최적화 함수로 사용\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "# 손실함수로는 MSELoss사용 / 인코더와 디코더에서 나온 값의 차이를 계산하기 위해 평균제곱오차 함수 사용\n"
      ],
      "metadata": {
        "id": "Iy_nJ291gXfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본 이미지 시각화 하기\n",
        "\n",
        "view_data = trainset.data[:5].view(-1, 28*28)\n",
        "view_data = view_data.type(torch.FloatTensor)/255."
      ],
      "metadata": {
        "id": "Gl_4V6iggx_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습하기 위한 함수\n",
        "def train(autoencoder, train_loader):\n",
        "    autoencoder.train()\n",
        "    for step, (x, label) in enumerate(train_loader):\n",
        "        x = x.view(-1, 28*28).to(DEVICE)\n",
        "        y = x.view(-1, 28*28).to(DEVICE) #x(입력)와 y(대상 레이블)모두 원본이미지(x)인 것을 주의해야 합니다.\n",
        "        label = label.to(DEVICE)\n",
        "        # 해당 train_loader의 스텝마다 x와 label값을 같이 가져오기 enumerate 사용\n",
        "\n",
        "        encoded, decoded = autoencoder(x)\n",
        "\n",
        "        loss = criterion(decoded, y) # decoded와 원본이미지(y) 사이의 평균제곱오차를 구합니다\n",
        "        optimizer.zero_grad() #기울기에 대한 정보를 초기화합니다.\n",
        "        loss.backward() # 기울기를 구합니다.\n",
        "        optimizer.step() #최적화를 진행합니다."
      ],
      "metadata": {
        "id": "VbCQ5taWkmza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습시작\n",
        "\n",
        "for epoch in range(1,EPOCH+1):\n",
        "  train(autoencoder, train_loader)\n",
        "\n",
        "  text_x = view_data.to(DEVICE)\n",
        "  _, decoded_data = autoencoder(text_x)\n",
        "\n",
        "  f,a = plt.subplots(2,5,figsize=(5,2))\n",
        "  print(\"[Epoch{}]\".format(epoch))\n",
        "  for i in range(5):\n",
        "    img = np.reshape(view_data.data.numpy()[i],(28,28))\n",
        "    a[0][i].imshow(img, cmap=\"gray\")\n",
        "    a[0][i].set_xticks(()); a[0][i].set_yticks(())\n",
        "\n",
        "  for i in range(5):\n",
        "    img = np.reshape(decoded_data.to(\"cpu\").data.numpy()[i], (28,28))\n",
        "    a[1][i].imshow(img,cmap='gray')\n",
        "    a[1][i].set_xticks(()); a[1][i].set_yticks(())\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "YfpWD_aBiHlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 잠재변수를 3D 플롯으로 시각화하기\n",
        "view_data = trainset.data[:200].view(-1,28*28) #원본 이미지 200개 준비하기\n",
        "view_data = view_data.type(torch.FloatTensor)/255.\n",
        "\n",
        "test_x = view_data.to(DEVICE)\n",
        "encoded_data, _ = autoencoder(test_x)\n",
        "encoded_data = encoded_data.to('cpu')"
      ],
      "metadata": {
        "id": "-pG24nPplm6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import cm\n",
        "\n",
        "CLASSES = {\n",
        "    0: 'T-shirt/top',\n",
        "    1: 'Trouser',\n",
        "    2: 'Pullover',\n",
        "    3: 'Dress',\n",
        "    4: 'Coat',\n",
        "    5: 'Sandal',\n",
        "    6: 'Shirt',\n",
        "    7: 'Sneaker',\n",
        "    8: 'Bag',\n",
        "    9: 'Ankle boot'\n",
        "}\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "X = encoded_data.data[:, 0].numpy()\n",
        "Y = encoded_data.data[:, 1].numpy()\n",
        "Z = encoded_data.data[:, 2].numpy()\n",
        "\n",
        "labels = trainset.targets[:200].numpy()\n",
        "\n",
        "for x, y, z, s in zip(X, Y, Z, labels):\n",
        "    name = CLASSES[s]\n",
        "    color = cm.rainbow(int(255 * s / 9))\n",
        "    ax.text(x, y, z, name, backgroundcolor=color)\n",
        "\n",
        "ax.set_xlim(X.min(), X.max())\n",
        "ax.set_ylim(Y.min(), Y.max())\n",
        "ax.set_zlim(Z.min(), Z.max())\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gY7I4PO-oJCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3d 상에 해당 LABEL이 잘 분류되어 있는지 분포를 시각화해봐도 !\n",
        "\n",
        "같은 레이블을 가진 이미지의 잠재변수는 같이 모여있음을 확인해볼 수 있었음 !!!"
      ],
      "metadata": {
        "id": "LaLBMNa8plCO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 오토인코더로 망가진 이미지 복원하기"
      ],
      "metadata": {
        "id": "Migvp9n4p0yY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 먼저 노이즈를 더하는 과정\n",
        "\n",
        "def add_noise(img):\n",
        "  noise = torch.randn(img.size()) *0.2\n",
        "  noisy_img = img + noise\n",
        "  return noisy_img\n"
      ],
      "metadata": {
        "id": "061chybrpDUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 코드에 노이즈 더하는 코드 추가하기\n",
        "\n",
        "def train(autoencoder,train_loader):\n",
        "  autoencoder.train()\n",
        "  avg_loss = 0\n",
        "\n",
        "  for step,(x,label) in enumerate(train_loader):\n",
        "     noisy_x = add_noise(x)\n",
        "     noisy_x = noisy_x.view(-1,28*28).to(DEVICE)\n",
        "     y = x.view(-1,28*28).to(DEVICE)\n",
        "\n",
        "     label = label.to(DEVICE)\n",
        "     encoded, decoded = autoencoder(noisy_x)\n",
        "\n",
        "     loss = criterion(decoded,y)\n",
        "     optimizer.zero_grad()\n",
        "     loss.backward()\n",
        "     optimizer.step()\n",
        "\n",
        "     avg_loss +=loss.item()\n",
        "    #  평균 오찻값 확인하기\n",
        "  return avg_loss / len(train_loader)\n"
      ],
      "metadata": {
        "id": "xr-Y9JKiqGk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1,EPOCH+1):\n",
        "  loss = train(autoencoder,train_loader)\n",
        "  print(\"[EPOCH {}] loss: {}\".format(epoch, loss))"
      ],
      "metadata": {
        "id": "GXRGoBhUrSeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 잡음제거 시각화\n",
        "\n",
        "testset = datasets.FashionMNIST(\n",
        "    root=\"./.data/\",\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = transforms.ToTensor()\n",
        ")\n",
        "\n",
        "# 테스트셋에서 이미지 한장을 가져오기\n",
        "sample_data = testset.data[0].view(-1,28*28)\n",
        "sample_data = sample_data.type(torch.FloatTensor)/255.\n",
        "\n",
        "original_x = sample_data[0]\n",
        "noisy_x = add_noise(original_x).to(DEVICE)\n",
        "_, recovered_x = autoencoder(noisy_x)"
      ],
      "metadata": {
        "id": "yqVrL5rgrcL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f,a = plt.subplots(1,3,figsize=(15,15))\n",
        "\n",
        "original_img = np.reshape(original_x.to('cpu').data.numpy(), (28,28))\n",
        "noisy_img = np.reshape(noisy_x.to('cpu').data.numpy(), (28,28))\n",
        "recovered_img = np.reshape(recovered_x.to('cpu').data.numpy(), (28,28))\n",
        "\n",
        "a[0].set_title(\"Original\")\n",
        "a[0].imshow(original_img, cmap=\"gray\")\n",
        "\n",
        "a[1].set_title('noisy_img')\n",
        "a[1].imshow(noisy_img, cmap='gray')\n",
        "\n",
        "\n",
        "a[2].set_title('Recovered')\n",
        "a[2].imshow(recovered_img, cmap='gray')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cGE5jbKWtD0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pbb-JTZitz6_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
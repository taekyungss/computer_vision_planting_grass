{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOATtVoRyWJcmmD92jgUmO3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taekyungss/computer_vision_planting_grass/blob/main/VAE_MLP%20%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98%20%EA%B5%AC%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucL5RWrYY7PW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import datasets,transforms\n",
        "from torchvision.utils import save_image\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = './images'\n",
        "channels = 1                    # MNIST has only 1\n",
        "\n",
        "n_epochs = 30\n",
        "batch_size = 128\n",
        "lr = 1e-3\n",
        "b1 = 0.5\n",
        "b2 = 0.999\n",
        "\n",
        "img_size = 28\n",
        "hidden_dim = 400\n",
        "latent_dim = 10"
      ],
      "metadata": {
        "id": "l_BftG4VZFaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(image_path, exist_ok = True)"
      ],
      "metadata": {
        "id": "IMzwtjy6ZWhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "JUEoPMcrZKpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data 불러오는 code / transform을 통해서는 데이터를 요리조리 가능 ex resize / augmentation등 가능\n",
        "transform = transforms.Compose([\n",
        "            transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# 각각의 데이터셋을 불러오기 => 여기서는 data를 datasets를 이용해서 받아와서 사용하도록 함\n",
        "\n",
        "train = datasets.MNIST(root = './data/', train=True, transform = transform, download=True)\n",
        "test = datasets.MNIST(root = './data/', train=False, transform = transform, download=True)\n",
        "\n",
        "# dataloader의 경우에는 해당 데이터셋을 불러오고 shuffle 즉 인덱스별로 순서대로 할건지 아님 섞을건지를 결정할 수 있도록 함\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True,\n",
        ")\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    test,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "VoRz6yqSZUqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reparameterization(mu, logvar):\n",
        "  std = torch.exp(logvar/2)\n",
        "  eps = torch.randn_like(std)\n",
        "  return mu+eps+std"
      ],
      "metadata": {
        "id": "W3cUs_tZaKYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, x_dim = img_size**2, h_dim = hidden_dim, z_dim = latent_dim):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    # 1st hidden layer\n",
        "    self.fc1 = nn.Sequential(\n",
        "        nn.Linear(x_dim,h_dim),\n",
        "        nn.ReLU(),\n",
        "         nn.Dropout(p=0.2)\n",
        "    )\n",
        "\n",
        "    self.fc2 = nn.Sequential(\n",
        "        nn.Linear(h_dim, h_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.2)\n",
        "    )\n",
        "\n",
        "    # output later\n",
        "    self.mu = nn.Linear(h_dim, z_dim)\n",
        "    self.logvar = nn.Linear(h_dim, z_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.fc(self.fc1(x))\n",
        "\n",
        "    mu = F.relu(self.mu(x))\n",
        "    logvar = F.relu(self.logvar(x))\n",
        "    z = reparameterization(mu,logvar)\n",
        "    return z, mu, logvar"
      ],
      "metadata": {
        "id": "K7BAbsFnaUeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, x_dim = img_size**2, h_dim = hidden_dim, z_dim = latent_dim):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    # 1st hidden layer\n",
        "    self.fc1 = nn.Sequential(\n",
        "        nn.Linear(z_dim, h_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.2)\n",
        "    )\n",
        "\n",
        "    # 2nd hidden layer\n",
        "    self.fc2 = nn.Sequential(\n",
        "        nn.Linear(h_dim, h_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.2)\n",
        "    )\n",
        "    # output layer\n",
        "    self.fc3 = nn.Linear(h_dim, x_dim)\n",
        "\n",
        "  def forward(self, z):\n",
        "    z = self.fc2(self,fc1(z))\n",
        "    x_reconst = F.sigmoid(self.fc3(z))\n",
        "    return x_reconst\n"
      ],
      "metadata": {
        "id": "lnb-EVVpb0YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder().to(device)\n",
        "decoder = Decoder().to(device)\n",
        "optimizer = torch.optim.Adam(\n",
        "    itertools.chain(encoder.parameters(), decoder.parameters()), lr=lr, betas=(b1, b2)\n",
        ")\n",
        "\n",
        "# 둘다 gpu device연결후, optimizer 설정 -> adam"
      ],
      "metadata": {
        "id": "eTJJQlwrcrl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoder)"
      ],
      "metadata": {
        "id": "xSNX015Xcvfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder)"
      ],
      "metadata": {
        "id": "bYZr-yFZdA3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epochs):\n",
        "    train_loss = 0\n",
        "    for i, (x, _) in enumerate(train_dataloader):\n",
        "        # forward\n",
        "        x = x.view(-1, img_size**2)\n",
        "        x = x.to(device)\n",
        "        z, mu, logvar = encoder(x)\n",
        "        x_reconst = decoder(z)\n",
        "\n",
        "        # compute reconstruction loss and KL divergence\n",
        "        reconst_loss = F.binary_cross_entropy(x_reconst, x, reduction='sum')\n",
        "        kl_div = 0.5 * torch.sum(mu.pow(2) + logvar.exp() - logvar - 1)\n",
        "\n",
        "        # backprop and optimize\n",
        "        loss = reconst_loss + kl_div\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        if (i+1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{n_epochs}], Step [{i+1}/{len(train_dataloader)}], Reconst Loss : {reconst_loss.item():.4f}, KL Div: {kl_div.item():.4f}')\n",
        "\n",
        "    print(f'===> Epoch: {epoch+1} Average Train Loss: {train_loss/len(train_dataloader.dataset):.4f} ')\n",
        "\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (x, _) in enumerate(test_dataloader):\n",
        "            # forward\n",
        "            x = x.view(-1, img_size**2)\n",
        "            x = x.to(device)\n",
        "            z, mu, logvar = encoder(x)\n",
        "            x_reconst = decoder(z)\n",
        "\n",
        "            # compute reconstruction loss and KL divergence\n",
        "            reconst_loss = F.binary_cross_entropy(x_reconst, x, reduction='sum')\n",
        "            kl_div = 0.5 * torch.sum(mu.pow(2) + logvar.exp() - logvar - 1)\n",
        "\n",
        "            loss = reconst_loss + kl_div\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # save reconstruction images\n",
        "            if i==0:\n",
        "                x_concat = torch.cat([x.view(-1, 1, 28, 28), x_reconst.view(-1, 1, 28, 28)], dim=3)\n",
        "                # batch size 개수만큼의 이미지 쌍(input x, reconstructed x)이 저장됨\n",
        "                save_image(x_concat, os.path.join(image_path,f'reconst-epoch{epoch+1}.png'))\n",
        "\n",
        "        print(f'===> Epoch: {epoch+1} Average Test Loss: {test_loss/len(test_dataloader.dataset):.4f} ')\n",
        "\n",
        "        # save sampled images\n",
        "        z = torch.randn(batch_size, latent_dim).to(device) # N(0, 1)에서 z 샘플링\n",
        "        sampled_images = decoder(z)\n",
        "        save_image(sampled_images.view(-1, 1, 28, 28), os.path.join(image_path,f'sampled-epoch{epoch+1}.png'))"
      ],
      "metadata": {
        "id": "LUj2mIGudB_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GN8twNLidEZE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN5aTO/wgPdjBTIY6fzXA3g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taekyungss/computer_vision_planting_grass/blob/main/VIT_pytorch_%EA%B5%AC%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "아직 미완"
      ],
      "metadata": {
        "id": "xrszysPBUdFB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubeK2iSeLs2C"
      },
      "outputs": [],
      "source": [
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from torch import optim\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from torchvision import utils\n",
        "\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "from PIL import Image\n",
        "from torchvision.transforms import Compose, Resize, ToTensor\n",
        "from einops import rearrange, reduce, repeat\n",
        "from einops.layers.torch import Rearrange, Reduce\n",
        "from torchsummary import summary\n",
        "import numpy as np\n",
        "import time\n",
        "import copy\n",
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "import math\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "BKuVQDIwMD6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path2data = '/content/data'\n",
        "\n",
        "if not os.path.exists(path2data):\n",
        "  os.mkdir(path2data)\n",
        "\n",
        "train_ds = datasets.STL10(path2data, split=\"train\", download=True, transform=transforms.ToTensor())\n",
        "val_ds = datasets.STL10(path2data, split=\"test\", download=True, transform = transforms.ToTensor())\n",
        "\n",
        "print(len(train_ds))\n",
        "print(len(val_ds))"
      ],
      "metadata": {
        "id": "3XYwY52lMmWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformation\n",
        "\n",
        "transformation = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize(224)\n",
        "])\n",
        "\n",
        "train_ds.transform = transformation\n",
        "val_ds.transform = transformation\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=32, shuffle = True)\n",
        "val_dl = DataLoader(val_ds, batch_size = 64, shuffle = True)"
      ],
      "metadata": {
        "id": "oRbBz3SvNX2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show(img, y=None):\n",
        "  npimg = img.numpy()\n",
        "  npimg_tr = np.transpose(npimg, (1,2,0))\n",
        "  plt.imshow(npimg_tr)\n",
        "\n",
        "  if y is not None:\n",
        "    plt.title(\"labels: \"+str(y))\n",
        "\n",
        "np.random.seed(10)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "grid_size=4\n",
        "rnd_ind = np.random.randint(0,len(train_ds), grid_size)\n",
        "\n",
        "x_grid = [train_ds[i][0] for i in rnd_ind]\n",
        "y_grid = [val_ds[i][1] for i in rnd_ind]\n",
        "\n",
        "x_grid = utils.make_grid(x_grid, nrow=grid_size, padding=2)\n",
        "plt.figure(figsize=(10,10))\n",
        "show(x_grid, y_grid)"
      ],
      "metadata": {
        "id": "1Co2N7geQcUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VIT 구현"
      ],
      "metadata": {
        "id": "iHV0pgsNQ_Yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# patch embedding\n",
        "\n",
        "class PatchEmbedding(nn.Module):\n",
        "  def __init__(self, in_channels=3, patch_size = 16, emb_size = 768, img_size = 224):\n",
        "    super().__init__()\n",
        "    self.patch_size = patch_size\n",
        "\n",
        "    self.projection = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, emb_size, patch_size , stride=patch_size),\n",
        "        # einops.rearrange는multidimensional tensor를 쉽게 reordering하는 함수입니다.\n",
        "        Rearrange('b e (h) (w) -> b (h w) e')\n",
        "    )\n",
        "\n",
        "    self.cls_token = nn.Parameter(torch.randn(1,1,emb_size))\n",
        "    self.positions = nn.Parameter(torch.randn((img_size // patch_size) **2 +1, emb_size))\n",
        "\n",
        "  def forward(self, x:Tensor) -> Tensor:\n",
        "    b = x.shape[0]\n",
        "    x = self.projection(x)\n",
        "    cls_tokens = repeat( self.cls_token, '() n e -> b n e', b=b)\n",
        "    # elnops -> repeat\n",
        "    x = torch.cat([cls_tokens, x], dim=1)\n",
        "    x+= self.positions\n",
        "    return x"
      ],
      "metadata": {
        "id": "sPQ3XdN-Q8r7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check\n",
        "\n",
        "x = torch.randn(16,3,224,224).to(device)\n",
        "patch_embedding = PatchEmbedding().to(device)\n",
        "patch_output = patch_embedding(x)\n",
        "print(\"[batch, 1+num of patches, emb_size] = \", patch_output.shape)"
      ],
      "metadata": {
        "id": "3cYV5bK4SuR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multiheadattention\n",
        "\n"
      ],
      "metadata": {
        "id": "DwzbnOuWUKxf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}